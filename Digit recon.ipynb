{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Digit Recognizer\n",
    "\n",
    "This is a Kaggle competition based on the MNIST dataset, considered the \"Hello World\" dataset of computer vision, one of the most wildely used datasets to measure machine learning models.\n",
    "\n",
    "The dataset contains handwritten images of digits, and I will try to build a model that recognizes this digits with a high precision. For this task I will use Convolutional Neural Networks, one of the best Deep Learning algorithms to recognize and understand images.\n",
    "\n",
    "Lets start by importing the necessary functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from keras import layers\n",
    "from keras.layers import Input, Add, Dense, Activation, ZeroPadding2D, BatchNormalization, Flatten, Conv2D, AveragePooling2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.models import Model, load_model\n",
    "from keras.preprocessing import image\n",
    "from keras.utils import layer_utils\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from keras.utils import plot_model\n",
    "from keras.initializers import glorot_uniform\n",
    "import scipy.misc\n",
    "from matplotlib.pyplot import imshow\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "%matplotlib inline\n",
    "\n",
    "import keras.backend as K\n",
    "K.set_image_data_format('channels_last')\n",
    "K.set_learning_phase(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading our datasets as a Pandas dataframe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(r\"C:\\Users\\juanv\\Desktop\\Programming\\Machine Learning\\Kaggle\\Datasets\\Digit recon\\train.csv\")\n",
    "test= pd.read_csv(r\"C:\\Users\\juanv\\Desktop\\Programming\\Machine Learning\\Kaggle\\Datasets\\Digit recon\\test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>pixel0</th>\n",
       "      <th>pixel1</th>\n",
       "      <th>pixel2</th>\n",
       "      <th>pixel3</th>\n",
       "      <th>pixel4</th>\n",
       "      <th>pixel5</th>\n",
       "      <th>pixel6</th>\n",
       "      <th>pixel7</th>\n",
       "      <th>pixel8</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel774</th>\n",
       "      <th>pixel775</th>\n",
       "      <th>pixel776</th>\n",
       "      <th>pixel777</th>\n",
       "      <th>pixel778</th>\n",
       "      <th>pixel779</th>\n",
       "      <th>pixel780</th>\n",
       "      <th>pixel781</th>\n",
       "      <th>pixel782</th>\n",
       "      <th>pixel783</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41996</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41997</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41998</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41999</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>42000 rows × 785 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       label  pixel0  pixel1  pixel2  pixel3  pixel4  pixel5  pixel6  pixel7  \\\n",
       "0          1       0       0       0       0       0       0       0       0   \n",
       "1          0       0       0       0       0       0       0       0       0   \n",
       "2          1       0       0       0       0       0       0       0       0   \n",
       "3          4       0       0       0       0       0       0       0       0   \n",
       "4          0       0       0       0       0       0       0       0       0   \n",
       "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "41995      0       0       0       0       0       0       0       0       0   \n",
       "41996      1       0       0       0       0       0       0       0       0   \n",
       "41997      7       0       0       0       0       0       0       0       0   \n",
       "41998      6       0       0       0       0       0       0       0       0   \n",
       "41999      9       0       0       0       0       0       0       0       0   \n",
       "\n",
       "       pixel8  ...  pixel774  pixel775  pixel776  pixel777  pixel778  \\\n",
       "0           0  ...         0         0         0         0         0   \n",
       "1           0  ...         0         0         0         0         0   \n",
       "2           0  ...         0         0         0         0         0   \n",
       "3           0  ...         0         0         0         0         0   \n",
       "4           0  ...         0         0         0         0         0   \n",
       "...       ...  ...       ...       ...       ...       ...       ...   \n",
       "41995       0  ...         0         0         0         0         0   \n",
       "41996       0  ...         0         0         0         0         0   \n",
       "41997       0  ...         0         0         0         0         0   \n",
       "41998       0  ...         0         0         0         0         0   \n",
       "41999       0  ...         0         0         0         0         0   \n",
       "\n",
       "       pixel779  pixel780  pixel781  pixel782  pixel783  \n",
       "0             0         0         0         0         0  \n",
       "1             0         0         0         0         0  \n",
       "2             0         0         0         0         0  \n",
       "3             0         0         0         0         0  \n",
       "4             0         0         0         0         0  \n",
       "...         ...       ...       ...       ...       ...  \n",
       "41995         0         0         0         0         0  \n",
       "41996         0         0         0         0         0  \n",
       "41997         0         0         0         0         0  \n",
       "41998         0         0         0         0         0  \n",
       "41999         0         0         0         0         0  \n",
       "\n",
       "[42000 rows x 785 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that each image is displayed as a values of pixels that range from 0 to 255 in only one channel (grey). Each row is an image, and each column represents a pixel except for the first one, \"label\" that contains the value of the digit represented in the image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking for missing values on the train and the test dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    785.0\n",
       "mean       0.0\n",
       "std        0.0\n",
       "min        0.0\n",
       "25%        0.0\n",
       "50%        0.0\n",
       "75%        0.0\n",
       "max        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.isnull().sum().describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    784.0\n",
       "mean       0.0\n",
       "std        0.0\n",
       "min        0.0\n",
       "25%        0.0\n",
       "50%        0.0\n",
       "75%        0.0\n",
       "max        0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.isnull().sum().describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No missing values. So we can proceed to divide our dataset into the features our model will train on, and the target that our model will try to hit. In this case the features are the pixel values and the target is the \"label\" column that contains the value of the digit we are trying to guess.\n",
    "\n",
    "We will call the features X_train, and the target Y_train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = train['label']\n",
    "X_train = train.drop('label',axis=1)\n",
    "\n",
    "\n",
    "X_test = test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that done now we need to reshape our data into an appropiate format for the Convolutional Neural Networks algorithm. That format is tipically: (number of images, rows, columns, channels) in our case channels will be set to 1 (grey images), in the typical RGB image channels would be set to 3.\n",
    "\n",
    "First convert to a numpy array so we can reshape the data (pandas does not allow to reshape a dataframe so easily)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.to_numpy()\n",
    "\n",
    "X_test = test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],28,28)\n",
    "\n",
    "X_test = X_test.reshape(X_test.shape[0],28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With that done lets take a look at the images on our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number:0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_train[5],cmap='gray', vmin=0, vmax=255)\n",
    "print('Number:' + str(Y_train[5]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalization\n",
    "\n",
    "Normalization is important so our model can converge faster on a data that ranges from 0 to 1 instead of 0 to 255.\n",
    "\n",
    "It also reduces the effect of illumination differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train/255.0\n",
    "\n",
    "X_test = X_test/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One hot enconding (label enconding)\n",
    "\n",
    "We will also convert the values in our target array to a more clear categorical data, by a process called one hot enconding. One hot enconding makes sure that our model wont think that our target values are ordinal. (ex : 3 -> [0,0,0,1,0,0,0,0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 10)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train= to_categorical(Y_train)\n",
    "Y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting our data into train/validation \n",
    "\n",
    "We will use 90% of our data to train our model, meaning that our model will iterate on this data to learn a certain combinations of parameters to try and predict future images. To measure the accuracy of our model we will test it on a part of our data (10%) that wasnt used to train the model. The former dataset is called the training dataset, and the latter the validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 28, 28, 1)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],28,28,1)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating artificial images\n",
    "\n",
    "The more data we have the more accurate will be our model. When we are lacking more data, and is not easy to find new data, one possible solution is to create this new data based on our old one. In our particular case we can generate some new images that will contain distortions, to simulate as accurate as possible the variations that happen when someone is writing a number.\n",
    "\n",
    "In this case we will rotate a bit the images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37800, 28, 28, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        zoom_range = 0.1, # Randomly zoom image \n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=False,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "\n",
    "datagen.fit(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Neural Network Structure\n",
    "\n",
    "Now that we are done messing with the data we will create our model.\n",
    "\n",
    "**Details about the structure:** \n",
    "\n",
    "Filter size: I decided to use multiple convolutional layers with small filters, size of (3x3), since multiple stacked smaller size filters are better than one with a larger filter size, because multiple non-linear layers increases the depth of the network which enables it to learn more complex features.\n",
    "\n",
    "Batch normalization: before each activation function to improve speed and performance. Batch normalization reduces the amount by what the hidden unit values shift around.\n",
    "\n",
    "Zero padding: \"pads\" the edges of the data matrix so it doesnt shrink in size after each CONV layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def DigitModel(input_shape):\n",
    "    \"\"\"\n",
    "    Implementation of the model.\n",
    "    \n",
    "    Arguments:\n",
    "    input_shape -- shape of the images of the dataset\n",
    "        (height, width, channels) as a tuple.  \n",
    "        Note that this does not include the 'batch' as a dimension.\n",
    "        If you have a batch like 'X_train', \n",
    "        then you can provide the input_shape using\n",
    "        X_train.shape[1:]\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "     #Define the input placeholder as a tensor with shape input_shape. \n",
    "    X_input = Input(input_shape)\n",
    "\n",
    "    # Zero-Padding: pads the border of X_input with zeroes\n",
    "    X = ZeroPadding2D((1, 1))(X_input)\n",
    "\n",
    "    # CONV -> BN -> RELU Block \n",
    "    X = Conv2D(16, (3, 3), strides = (1, 1), name = 'conv0',padding='same')(X)\n",
    "    X = BatchNormalization(axis = -1, name = 'bn0')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(32, (3, 3), strides = (1, 1), name = 'conv1',padding='same')(X)\n",
    "    X = BatchNormalization(axis = -1, name = 'bn1')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(64, (3, 3), strides = (1, 1), name = 'conv2',padding='same')(X)\n",
    "    X = BatchNormalization(axis = -1, name = 'bn2')(X)\n",
    "    X = Activation('relu')(X)\n",
    "\n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool0')(X)\n",
    "    \n",
    "    # CONV -> BN -> RELU Block\n",
    "    X = Conv2D(64, (3, 3), strides = (1, 1), name = 'conv3',padding='same')(X)\n",
    "    X = BatchNormalization(axis = -1, name = 'bn3')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    X = Conv2D(128, (3, 3), strides = (1, 1), name = 'conv4',padding='same')(X)\n",
    "    X = BatchNormalization(axis = -1, name = 'bn4')(X)\n",
    "    X = Activation('relu')(X)\n",
    "    \n",
    "    # MAXPOOL\n",
    "    X = MaxPooling2D((2, 2), name='max_pool1')(X)\n",
    "\n",
    "    # FLATTEN X (convert it to a vector) + FC layer\n",
    "    X = Flatten()(X)\n",
    "    X = Dense(512, activation='relu', name='fc0')(X)\n",
    "    X = BatchNormalization(axis = -1, name = 'bn5')(X)\n",
    "    X = Dense(10, activation='softmax', name='fc1')(X)\n",
    "\n",
    "    # Create model.\n",
    "    model = Model(inputs = X_input, outputs = X, name='DigitModel')\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Lets proceed to train our model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_model = DigitModel((28,28,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_model.compile(optimizer = \"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2363/2363 [==============================] - 32s 13ms/step - loss: 0.0350 - accuracy: 0.9879\n",
      "Epoch 2/10\n",
      "2363/2363 [==============================] - 29s 12ms/step - loss: 0.0174 - accuracy: 0.9942\n",
      "Epoch 3/10\n",
      "2363/2363 [==============================] - 30s 13ms/step - loss: 0.0134 - accuracy: 0.9954\n",
      "Epoch 4/10\n",
      "2363/2363 [==============================] - 32s 13ms/step - loss: 0.0119 - accuracy: 0.9960\n",
      "Epoch 5/10\n",
      "2363/2363 [==============================] - 32s 13ms/step - loss: 0.0105 - accuracy: 0.9966\n",
      "Epoch 6/10\n",
      "2363/2363 [==============================] - 30s 13ms/step - loss: 0.0094 - accuracy: 0.9969\n",
      "Epoch 7/10\n",
      "2363/2363 [==============================] - 30s 12ms/step - loss: 0.0081 - accuracy: 0.9973\n",
      "Epoch 8/10\n",
      "2363/2363 [==============================] - 30s 13ms/step - loss: 0.0080 - accuracy: 0.9974\n",
      "Epoch 9/10\n",
      "2363/2363 [==============================] - 31s 13ms/step - loss: 0.0079 - accuracy: 0.9974\n",
      "Epoch 10/10\n",
      "2363/2363 [==============================] - 29s 12ms/step - loss: 0.0067 - accuracy: 0.9977\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x2031aa5ca48>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digit_model.fit_generator(datagen.flow(X_train, Y_train, batch_size=16), epochs = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation \n",
    "\n",
    "Our model achieved an accuracy of 99.77% on our training data, lets check how it performs on the validation data, so we can make sure is not over-fitting (adjusting too much to our training data, but failing to generalize to new data it hasnt seen before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200/4200 [==============================] - 1s 172us/step\n",
      "Loss = 0.005318367086736197\n",
      "Test Accuracy = 0.9980002641677856\n"
     ]
    }
   ],
   "source": [
    "X_val = X_val.reshape((X_val.shape[0],28,28,1))\n",
    "\n",
    "preds = digit_model.evaluate(X_val, Y_val)\n",
    "print (\"Loss = \" + str(preds[0]))\n",
    "print (\"Test Accuracy = \" + str(preds[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model achieved an accuracy of 99.80% on our test data, so is not overfitting!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit to Kaggle\n",
    "\n",
    "Lets submit our models prediction to Kaggle to see how we score compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 0, 9, ..., 3, 9, 2], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = digit_model.predict(X_test, verbose=0)\n",
    "\n",
    "predictions = predictions.argmax(axis=1)\n",
    "\n",
    "submissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n",
    "                         \"Label\": predictions})\n",
    "submissions.to_csv(\"digit1.csv\", index=False, header=True)\n",
    "\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 99.25% accuracy in Kaggle\n",
    "\n",
    "Position 583 out of 2290 around submission time. Top 25%.\n",
    "\n",
    "jvmd95"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
